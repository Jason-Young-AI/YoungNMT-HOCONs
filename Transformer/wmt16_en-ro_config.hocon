binaries {
  preprocess {
    logger {
      name = "preprocess_wmt16_en-ro"
      off = false
      path = "preprocess_wmt16_en-ro.log"
    }
    random_seed = 1234
    task = "seq2seq"
  }
  test {
    checkpoint_directory = "Checkpoints/WMT16_En-Ro"
    device = "GPU"
    logger {
      name = "test_wmt16_en-ro_newsdev2016"
      off = false
      path = "test_wmt16_en-ro_newsdev2016.log"
    }
    output_directory = "Outputs/WMT16_En-Ro"
    task = "seq2seq"
    tester = "seq2seq"
  }
  train {
    checkpoint = ""
    distribution {
      device = "GPU"
      master_ip = "127.0.0.1"
      master_port = "23333"
      ranks = [
        0
        1
        2
        3
      ]
      workshop_capacity = 60
      world_size = 4
    }
    logger {
      name = "train_wmt16_en-ro"
      off = false
      path = "train_wmt16_en-ro.log"
    }
    mix_precision {
      on = false
      optimization_level = "O0"
    }
    model = "transformer_base"
    optimizer {
      beta1 = 0.9
      beta2 = 0.98
      epsilon = 1e-09
      learning_rate = 0.001
      name = "adam"
    }
    random_seed = 1234
    reset_optimizer = false
    reset_scheduler = false
    reset_trainer = false
    scheduler {
      name = "noam"
      warmup_step = 4000
    }
    task = "seq2seq"
    trainer = "seq2seq"
    visualizer {
      name = "seq2seq_wmt16_en-ro"
      off = true
      offline = true
      overwrite = true
      password = "Happy_Visual_001"
      path = "seq2seq_wmt16_en-ro.vis"
      port = 6789
      server = "www.young-leigh.love"
      username = "Guest_Visdom"
    }
  }
}
models {
  transformer_base {
    decoder {
      attention_dropout_probability = 0.1
      dimension = 512
      dropout_probability = 0.1
      feedforward_dimension = 2048
      feedforward_dropout_probability = 0.1
      head_number = 8
      layer_number = 6
      normalize_position = "before"
    }
    dimension = 512
    encoder {
      attention_dropout_probability = 0.1
      dimension = 512
      dropout_probability = 0.1
      feedforward_dimension = 2048
      feedforward_dropout_probability = 0.1
      head_number = 8
      layer_number = 6
      normalize_position = "before"
    }
    name = "transformer"
    share_dec_io_embeddings = true
    share_enc_dec_embeddings = true
  }
}
tasks {
  seq2seq {
    datasets {
      training = "Datasets/wmt16.en-ro.dataset"
      validation = "Datasets/newsdev2016.en-ro.dataset"
      vocabularies = "Datasets/wmt16.en-ro.vocab"
    }
    language {
      source = "'en'"
      target = "'ro'"
    }
    name = "seq2seq"
    number_worker = 16
    raw_data {
      training {
        source = "Corpora/wmt16.en-ro.en"
        target = "Corpora/wmt16.en-ro.ro"
      }
      validation {
        source = "Corpora/newsdev2016.en-ro.en"
        target = "Corpora/newsdev2016.en-ro.ro"
      }
    }
    shard_size = 1000000
    training_batches {
      batch_size = 4096
      batch_type = "token"
      dock_size = 8192
      export_volume = 2
      filter {
        source = [
          0
          200
        ]
        target = [
          0
          200
        ]
      }
      shuffle = true
    }
    validation_batches {
      batch_size = 32
      batch_type = "sentence"
    }
    vocabularies {
      share = true
      size_limit {
        source = 32768
        target = 32768
      }
    }
    work_amount = 40000
  }
}
testers {
  seq2seq {
    batch_size = 80
    batch_type = "sentence"
    bpe_symbol = "@@ "
    name = "seq2seq"
    remove_bpe = true
    searcher {
      beam_size = 4
      max_length = 200
      min_length = 1
      n_best = 1
      name = "beam"
      penalty {
        alpha = 0.6
        beta = 0.0
      }
    }
    source = "Corpora/newsdev2016.en-ro.en"
    target = "Corpora/Gold/newsdev2016.en-ro.ro"
  }
}
trainers {
  seq2seq {
    checkpoints {
      directory = "Checkpoints/WMT16_En-Ro"
      keep_number = 100
      name = "seq2seq_wmt16_en-ro"
    }
    life_cycle = 30000
    name = "seq2seq"
    normalization_type = "token"
    report_period = 1
    training_criterion {
      label_smoothing_percent = 0.1
      name = "label_smoothing_cross_entropy"
    }
    training_period = 1000
    validation_criterion {
      name = "cross_entropy"
    }
    validation_period = 1000
  }
}